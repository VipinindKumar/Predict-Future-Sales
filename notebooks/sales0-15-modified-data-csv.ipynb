{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom itertools import product","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54217075a8b87145457b2b9491acc967e31ed14d"},"cell_type":"code","source":"sales = pd.read_csv('../input/sales_train.csv')\nsales.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a10835f74fa38f56f194c86dcbe547722c1fcd6"},"cell_type":"code","source":"items = pd.read_csv('../input/items.csv')\ntest = pd.read_csv('../input/test.csv')\nitem_categories = pd.read_csv('../input/item_categories.csv')\nshops = pd.read_csv('../input/shops.csv')\n\nsales['date'] = pd.to_datetime(sales['date'], format='%d.%m.%Y')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb8d139431d4efe0e37275a94f875efb2e4d05ed"},"cell_type":"markdown","source":"- prediction are need to be made based on monthly data"},{"metadata":{"trusted":true,"_uuid":"03118ab9575058474f5de42ea3e59634e8ec9e34"},"cell_type":"code","source":"# create grid of shop and items and add sum() of their item_cnt_day (0 for NaN)\nindex_cols = ['date_block_num', 'shop_id', 'item_id']\n\n# For every month we create a grid from all shops/items combinations from that month\ngrid = [] \nfor block_num in sales['date_block_num'].unique():\n    cur_shops = sales[sales['date_block_num']==block_num]['shop_id'].unique()\n    cur_items = sales[sales['date_block_num']==block_num]['item_id'].unique()\n    grid.append(np.array(list(product(*[[block_num], cur_shops, cur_items])),dtype='int32'))\n\n#turn the grid into pandas dataframe\ngrid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n\n#####################\n#get aggregated values for (shop_id, item_id, month)\n#gb = sales.groupby(index_cols,as_index=False).agg({'item_cnt_day':{'target': 'sum'}})\n#fix column names\n#gb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values]\n\n# alternative way to sum item_cnt_day, without warning from pandas for using dict in agg()\ngb = sales.groupby(index_cols,as_index=False).item_cnt_day.sum()\ngb = gb.rename(columns={'item_cnt_day': 'item_cnt_month'})\n#####################\n\n#join aggregated data to the grid\nall_data = pd.merge(grid,gb,how='left',on=index_cols).fillna(0)\n\n#sort the data\nall_data.sort_values(['date_block_num','shop_id','item_id'],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63c3384e34aa47fb27d49bef99f52ea545cff02b"},"cell_type":"code","source":"all_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fbab3d6d0ae25448c3fd816bd3fe7a5217dc4769"},"cell_type":"markdown","source":"- Create target mean encoding feature with CV loop regularization using KFold"},{"metadata":{"trusted":true,"_uuid":"2b679a211c1721571abe16114c4c89a5f23c8138"},"cell_type":"code","source":"from sklearn.model_selection import KFold\n\nkf = KFold(n_splits=5, shuffle=False)\n\nall_data['item_target_enc'] = np.NaN\n\nfor rest, curr in kf.split(all_data):\n    # divide the data using folds\n    #rest_fold, cur_fold = all_data[rest], all_data[curr]\n    \n    # use rest_fold to calculate mean target\n    #all_data.iloc[curr]['item_target_enc'] = all_data.iloc[rest].groupby('item_id')['item_cnt_month'].transform('mean')\n    # 8e-16\n    # should be all_data.iloc[curr, all_data.columns.get_loc('item_target_enc')]\n    \n    #item_id_target_mean = all_data.iloc[rest].groupby('item_id').item_cnt_month.mean()\n    #all_data.ix[curr,'item_target_enc'] = all_data['item_id'].map(item_id_target_mean)\n    #.ix is depreciated\n    # 0.41650796922\n    \n    item_id_target_mean = all_data.iloc[rest].groupby('item_id').item_cnt_month.mean()\n    all_data.loc[all_data.index[curr],'item_target_enc'] = all_data['item_id'].map(item_id_target_mean)\n    # 0.4164590712798811\n    \n    #all_data.ix[curr, 'item_target_enc'] = all_data.iloc[rest].groupby('item_id')['item_cnt_month'].transform('mean')\n    # 0.0801429988734\n    \n# Fill NaNs\nall_data['item_target_enc'].fillna(0.33427, inplace=True)\n\nencoded_feature = all_data['item_target_enc'].values\n\n# compute correlation\nnp.corrcoef(all_data['item_cnt_month'].values, encoded_feature)[0][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14838d42969cf958f8b9d9450a1f92b742f1a1fd"},"cell_type":"code","source":"all_data.item_cnt_month.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"189747fd50d806c7b3c228a485a7e4466e771774"},"cell_type":"code","source":"all_data.to_csv('all_data.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01902dce665245903dd2b580dac78b4f404dc69c"},"cell_type":"code","source":"pd.read_csv('all_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9faba65c64b5c2c2acf637de96930387025706c8"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}